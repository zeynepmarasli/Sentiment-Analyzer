{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score\n",
    "from HappyFunTokenizer import HappyFunTokenizer\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "import os \n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rel_path(file_name):\n",
    "    absolutepath = os.path.abspath('')\n",
    "    #print(absolutepath)\n",
    "    fileDirectory = os.path.dirname(absolutepath)\n",
    "    file_path = os.path.join(fileDirectory, 'Data/' + str(file_name))   \n",
    "    #print(file_path)\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load preprocessed dataset from csv\n",
    "file = get_rel_path(\"data.csv\")\n",
    "df_data = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>27994</th>\n",
       "      <th>27995</th>\n",
       "      <th>27996</th>\n",
       "      <th>27997</th>\n",
       "      <th>27998</th>\n",
       "      <th>27999</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Pos:Neg Ratio</th>\n",
       "      <th>Length</th>\n",
       "      <th>Noun Phrases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.137931</td>\n",
       "      <td>491</td>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032258</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.243902</td>\n",
       "      <td>856</td>\n",
       "      <td>196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035964</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3.250000</td>\n",
       "      <td>345</td>\n",
       "      <td>86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.343066</td>\n",
       "      <td>783</td>\n",
       "      <td>187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.049475</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>909</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066302</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.613636</td>\n",
       "      <td>663</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.021153</td>\n",
       "      <td>0.021478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>899</td>\n",
       "      <td>217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.032394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.733119</td>\n",
       "      <td>2039</td>\n",
       "      <td>479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.644068</td>\n",
       "      <td>634</td>\n",
       "      <td>157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043672</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.208556</td>\n",
       "      <td>808</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 28004 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2    3    4         5         6    7    8    9  ...  27994  \\\n",
       "0     0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.0  0.0  0.0  ...    0.0   \n",
       "1     0.0  0.0  0.0  0.0  0.0  0.000000  0.032258  0.0  0.0  0.0  ...    0.0   \n",
       "2     0.0  0.0  0.0  0.0  0.0  0.000000  0.035964  0.0  0.0  0.0  ...    0.0   \n",
       "3     0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.0  0.0  0.0  ...    0.0   \n",
       "4     0.0  0.0  0.0  0.0  0.0  0.000000  0.049475  0.0  0.0  0.0  ...    0.0   \n",
       "...   ...  ...  ...  ...  ...       ...       ...  ...  ...  ...  ...    ...   \n",
       "1995  0.0  0.0  0.0  0.0  0.0  0.000000  0.066302  0.0  0.0  0.0  ...    0.0   \n",
       "1996  0.0  0.0  0.0  0.0  0.0  0.021153  0.021478  0.0  0.0  0.0  ...    0.0   \n",
       "1997  0.0  0.0  0.0  0.0  0.0  0.000000  0.032394  0.0  0.0  0.0  ...    0.0   \n",
       "1998  0.0  0.0  0.0  0.0  0.0  0.000000  0.000000  0.0  0.0  0.0  ...    0.0   \n",
       "1999  0.0  0.0  0.0  0.0  0.0  0.000000  0.043672  0.0  0.0  0.0  ...    0.0   \n",
       "\n",
       "      27995  27996  27997  27998  27999  Sentiment  Pos:Neg Ratio  Length  \\\n",
       "0       0.0    0.0    0.0    0.0    0.0          1       3.137931     491   \n",
       "1       0.0    0.0    0.0    0.0    0.0          1       0.243902     856   \n",
       "2       0.0    0.0    0.0    0.0    0.0          1       3.250000     345   \n",
       "3       0.0    0.0    0.0    0.0    0.0          1       0.343066     783   \n",
       "4       0.0    0.0    0.0    0.0    0.0          0       0.541667     909   \n",
       "...     ...    ...    ...    ...    ...        ...            ...     ...   \n",
       "1995    0.0    0.0    0.0    0.0    0.0          0       0.613636     663   \n",
       "1996    0.0    0.0    0.0    0.0    0.0          0       0.863636     899   \n",
       "1997    0.0    0.0    0.0    0.0    0.0          1       0.733119    2039   \n",
       "1998    0.0    0.0    0.0    0.0    0.0          0       1.644068     634   \n",
       "1999    0.0    0.0    0.0    0.0    0.0          1       0.208556     808   \n",
       "\n",
       "      Noun Phrases  \n",
       "0              112  \n",
       "1              196  \n",
       "2               86  \n",
       "3              187  \n",
       "4              217  \n",
       "...            ...  \n",
       "1995           140  \n",
       "1996           217  \n",
       "1997           479  \n",
       "1998           157  \n",
       "1999           193  \n",
       "\n",
       "[2000 rows x 28004 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import shuffle\n",
    "df_data = shuffle(df_data)\n",
    "df_data.reset_index(inplace=True, drop=True)\n",
    "df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to take as input training and testing vectors and labels\n",
    "# Allow this to be extensible to let multiple classifiers be used here\n",
    "def buildClassifiers(clf, X_train, X_test, y_train, y_test):\n",
    "\n",
    "    #clf.fit(X_train.todense(), y_train)\n",
    "    #y_pred = clf.predict(X_test.todense())\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "    precision = precision_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "\n",
    "    return f1, precision, recall\n",
    "\n",
    "def train_and_evaluate(X_train, X_test, y_train, y_test):\n",
    "    names = ['Naive_Bayes', 'Decision_Tree', 'Linear SVM', 'Random Forest']\n",
    "    classifiers = [GaussianNB(), \n",
    "                   DecisionTreeClassifier(random_state=42),\n",
    "                  LinearSVC(dual=True, C= 0.024, max_iter=3000),\n",
    "                  #RandomForestClassifier(max_depth=2, random_state=0)\n",
    "                   RandomForestClassifier()\n",
    "                  ]\n",
    "    aList, bList, cList = list(), list(), list()\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        print('Now classifying', name)\n",
    "        f1, precision, recall = buildClassifiers(clf, X_train, X_test,  \n",
    "                                                     y_train, y_test)\n",
    "        aList.append(f1)\n",
    "        bList.append(precision)\n",
    "        cList.append(recall)\n",
    "\n",
    "        print(\"\\tF1 for {}:\\t\\t\".format(name), np.mean(aList))\n",
    "        print(\"\\tPrecision for {}:\\t\".format(name), np.mean(bList))\n",
    "        print(\"\\tRecall for {}:\\t\\t\".format(name), np.mean(cList))\n",
    "        print()\n",
    "    return aList, bList, cList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline\n",
    "    X = tf-idf matrix (negation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2000, 28000)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_data.drop(['Sentiment', 'Pos:Neg Ratio', 'Length', 'Noun Phrases'], axis = 1)\n",
    "y = df_data['Sentiment']\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now classifying Naive_Bayes\n",
      "\tF1 for Naive_Bayes:\t\t 0.6828861727086961\n",
      "\tPrecision for Naive_Bayes:\t 0.6880573616715068\n",
      "\tRecall for Naive_Bayes:\t\t 0.6830519074421513\n",
      "\n",
      "Now classifying Decision_Tree\n",
      "\tF1 for Decision_Tree:\t\t 0.6452237552088567\n",
      "\tPrecision for Decision_Tree:\t 0.6477786808357533\n",
      "\tRecall for Decision_Tree:\t\t 0.6453095684803002\n",
      "\n",
      "Now classifying Linear SVM\n",
      "\tF1 for Linear SVM:\t\t 0.7067818291541829\n",
      "\tPrecision for Linear SVM:\t 0.7090827421792424\n",
      "\tRecall for Linear SVM:\t\t 0.7071711486345632\n",
      "\n",
      "Now classifying Random Forest\n",
      "\tF1 for Random Forest:\t\t 0.7274759866437404\n",
      "\tPrecision for Random Forest:\t 0.7302719067820137\n",
      "\tRecall for Random Forest:\t\t 0.7282207629768604\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2,random_state=109)\n",
    "\n",
    "overall_f1, overall_precision, overall_recall = train_and_evaluate(X_train, X_test, \n",
    "                                                                   y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPROVED SYSTEM\n",
    "    Features:\n",
    "        - tf-idf matrix (negation)\n",
    "        - pos:neg words ratio\n",
    "        - review length \n",
    "        - # of noun phrases "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negation + Pos:Neg Ratio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now classifying Naive_Bayes\n",
      "\tF1 for Naive_Bayes:\t\t 0.6828861727086961\n",
      "\tPrecision for Naive_Bayes:\t 0.6880573616715068\n",
      "\tRecall for Naive_Bayes:\t\t 0.6830519074421513\n",
      "\n",
      "Now classifying Decision_Tree\n",
      "\tF1 for Decision_Tree:\t\t 0.6576482499333784\n",
      "\tPrecision for Decision_Tree:\t 0.6601344500665226\n",
      "\tRecall for Decision_Tree:\t\t 0.657567229518449\n",
      "\n",
      "Now classifying Linear SVM\n",
      "\tF1 for Linear SVM:\t\t 0.665830275513127\n",
      "\tPrecision for Linear SVM:\t 0.6749494932375416\n",
      "\tRecall for Linear SVM:\t\t 0.6686679174484053\n",
      "\n",
      "Now classifying Random Forest\n",
      "\tF1 for Random Forest:\t\t 0.6999856708015796\n",
      "\tPrecision for Random Forest:\t 0.7070835141589253\n",
      "\tRecall for Random Forest:\t\t 0.7022983114446528\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df_data.drop(['Sentiment', 'Length', 'Noun Phrases'], axis =1)\n",
    "X = df.to_numpy()\n",
    "y = df_data[\"Sentiment\"].to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2,random_state=109)\n",
    "overall_f1, overall_precision, overall_recall = train_and_evaluate(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negation + Pos:Neg Ratio + Noun Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now classifying Naive_Bayes\n",
      "\tF1 for Naive_Bayes:\t\t 0.7124299179328837\n",
      "\tPrecision for Naive_Bayes:\t 0.7133413461538461\n",
      "\tRecall for Naive_Bayes:\t\t 0.7131332082551595\n",
      "\n",
      "Now classifying Decision_Tree\n",
      "\tF1 for Decision_Tree:\t\t 0.6811887083101755\n",
      "\tPrecision for Decision_Tree:\t 0.6819816790592514\n",
      "\tRecall for Decision_Tree:\t\t 0.6818323952470293\n",
      "\n",
      "Now classifying Linear SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zeynepmarasli/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tF1 for Linear SVM:\t\t 0.6822591703645541\n",
      "\tPrecision for Linear SVM:\t 0.6872933415950566\n",
      "\tRecall for Linear SVM:\t\t 0.6845945382530747\n",
      "\n",
      "Now classifying Random Forest\n",
      "\tF1 for Random Forest:\t\t 0.7077747217199072\n",
      "\tPrecision for Random Forest:\t 0.713039107561852\n",
      "\tRecall for Random Forest:\t\t 0.7101000625390868\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df_data.drop(['Sentiment', 'Length'], axis =1)\n",
    "X = df.to_numpy()\n",
    "y = df_data[\"Sentiment\"].to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2,random_state=109)\n",
    "overall_f1, overall_precision, overall_recall = train_and_evaluate(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All features: Negation + Pos:Neg Ratio + Review length + Noun phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now classifying Naive_Bayes\n",
      "\tF1 for Naive_Bayes:\t\t 0.791653400936331\n",
      "\tPrecision for Naive_Bayes:\t 0.7991811616315736\n",
      "\tRecall for Naive_Bayes:\t\t 0.7943089430894309\n",
      "\n",
      "Now classifying Decision_Tree\n",
      "\tF1 for Decision_Tree:\t\t 0.7107618710521308\n",
      "\tPrecision for Decision_Tree:\t 0.7144406522103608\n",
      "\tRecall for Decision_Tree:\t\t 0.7119136960600376\n",
      "\n",
      "Now classifying Linear SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zeynepmarasli/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tF1 for Linear SVM:\t\t 0.6150037343064362\n",
      "\tPrecision for Linear SVM:\t 0.6771826570291294\n",
      "\tRecall for Linear SVM:\t\t 0.6493016468626225\n",
      "\n",
      "Now classifying Random Forest\n",
      "\tF1 for Random Forest:\t\t 0.6580510434633945\n",
      "\tPrecision for Random Forest:\t 0.7054765660407681\n",
      "\tRecall for Random Forest:\t\t 0.6841463414634146\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df_data.drop(['Sentiment'], axis =1)\n",
    "X = df.to_numpy()\n",
    "y = df_data[\"Sentiment\"].to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2,random_state=109)\n",
    "overall_f1, overall_precision, overall_recall = train_and_evaluate(X_train, X_test, y_train, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
