{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, accuracy_score\n",
    "from HappyFunTokenizer import HappyFunTokenizer\n",
    "from sklearn_pandas import DataFrameMapper\n",
    "import os \n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rel_path(file_name):\n",
    "    absolutepath = os.path.abspath('')\n",
    "    #print(absolutepath)\n",
    "    fileDirectory = os.path.dirname(absolutepath)\n",
    "    file_path = os.path.join(fileDirectory, 'Data/ExtraCredit/' + str(file_name))   \n",
    "    #print(file_path)\n",
    "    return file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load preprocessed dataset from csv\n",
    "file = get_rel_path(\"data_extracredit.csv\")\n",
    "df_data = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "df_data = shuffle(df_data)\n",
    "df_data.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>14549</th>\n",
       "      <th>14550</th>\n",
       "      <th>14551</th>\n",
       "      <th>14552</th>\n",
       "      <th>14553</th>\n",
       "      <th>14554</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Pos:Neg Ratio</th>\n",
       "      <th>Length</th>\n",
       "      <th>Noun Phrases</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.045057</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.777778</td>\n",
       "      <td>118.0</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.152409</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>62.0</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>247.0</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.025640</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>11.285714</td>\n",
       "      <td>346.0</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10386</th>\n",
       "      <td>0.097558</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.625000</td>\n",
       "      <td>121.0</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10387</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10388</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>76.0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10389</th>\n",
       "      <td>0.241159</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>33.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10390</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>124.0</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8781 rows × 14559 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0    1    2    3    4    5    6    7    8    9  ...  14549  \\\n",
       "0      0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "2      0.045057  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "3      0.152409  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "5      0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "6      0.025640  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "...         ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...    ...   \n",
       "10386  0.097558  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "10387  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "10388  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "10389  0.241159  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "10390  0.000000  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...    0.0   \n",
       "\n",
       "       14550  14551  14552  14553  14554  Sentiment  Pos:Neg Ratio  Length  \\\n",
       "0        0.0    0.0    0.0    0.0    0.0          1       6.000000    40.0   \n",
       "2        0.0    0.0    0.0    0.0    0.0          0       1.777778   118.0   \n",
       "3        0.0    0.0    0.0    0.0    0.0          1       4.666667    62.0   \n",
       "5        0.0    0.0    0.0    0.0    0.0          1      14.000000   247.0   \n",
       "6        0.0    0.0    0.0    0.0    0.0          1      11.285714   346.0   \n",
       "...      ...    ...    ...    ...    ...        ...            ...     ...   \n",
       "10386    0.0    0.0    0.0    0.0    0.0          1       2.625000   121.0   \n",
       "10387    0.0    0.0    0.0    0.0    0.0          1       0.800000    22.0   \n",
       "10388    0.0    0.0    0.0    0.0    0.0          1       6.000000    76.0   \n",
       "10389    0.0    0.0    0.0    0.0    0.0          1       1.500000    33.0   \n",
       "10390    0.0    0.0    0.0    0.0    0.0          1       0.684211   124.0   \n",
       "\n",
       "       Noun Phrases  \n",
       "0                 7  \n",
       "2                30  \n",
       "3                17  \n",
       "5                55  \n",
       "6                78  \n",
       "...             ...  \n",
       "10386            27  \n",
       "10387             4  \n",
       "10388            21  \n",
       "10389            12  \n",
       "10390            34  \n",
       "\n",
       "[8781 rows x 14559 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = df_data.dropna()\n",
    "df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to take as input training and testing vectors and labels\n",
    "# Allow this to be extensible to let multiple classifiers be used here\n",
    "def buildClassifiers(clf, X_train, X_test, y_train, y_test):\n",
    "\n",
    "    #clf.fit(X_train.todense(), y_train)\n",
    "    #y_pred = clf.predict(X_test.todense())\n",
    "    \n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    \n",
    "    f1 = f1_score(y_test, y_pred, average=\"weighted\", zero_division=0)\n",
    "    precision = precision_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "    recall = recall_score(y_test, y_pred, average=\"macro\", zero_division=0)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    return f1, precision, recall, accuracy\n",
    "\n",
    "def train_and_evaluate(X_train, X_test, y_train, y_test):\n",
    "    names = ['Naive_Bayes', 'Decision_Tree', 'Linear SVM', 'Random Forest']\n",
    "    classifiers = [GaussianNB(), \n",
    "                   DecisionTreeClassifier(random_state=42),\n",
    "                  LinearSVC(dual=True, C= 0.024, max_iter=3000),\n",
    "                  #RandomForestClassifier(max_depth=2, random_state=0)\n",
    "                   RandomForestClassifier()\n",
    "                  ]\n",
    "    aList, bList, cList, dList = list(), list(), list(), list()\n",
    "    for name, clf in zip(names, classifiers):\n",
    "        print('Now classifying', name)\n",
    "        f1, precision, recall, accuracy = buildClassifiers(clf, X_train, X_test,  \n",
    "                                                     y_train, y_test)\n",
    "        aList.append(f1)\n",
    "        bList.append(precision)\n",
    "        cList.append(recall)\n",
    "        dList.append(accuracy)\n",
    "\n",
    "        print(\"\\tF1 for {}:\\t\\t\".format(name), np.mean(aList))\n",
    "        print(\"\\tPrecision for {}:\\t\".format(name), np.mean(bList))\n",
    "        print(\"\\tRecall for {}:\\t\\t\".format(name), np.mean(cList))\n",
    "        print(\"\\tAccuracy for {}:\\t\\t\".format(name), np.mean(dList))\n",
    "        print()\n",
    "    return aList, bList, cList, dList"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline\n",
    "    X = tf-idf matrix (negation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8781, 14555)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df_data.drop(['Sentiment', 'Pos:Neg Ratio', 'Length', 'Noun Phrases'], axis = 1)\n",
    "y = df_data['Sentiment']\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now classifying Naive_Bayes\n",
      "\tF1 for Naive_Bayes:\t\t 0.7309179086590009\n",
      "\tPrecision for Naive_Bayes:\t 0.73264745458623\n",
      "\tRecall for Naive_Bayes:\t\t 0.7272009073487427\n",
      "\tAccuracy for Naive_Bayes:\t\t 0.732498577120091\n",
      "\n",
      "Now classifying Decision_Tree\n",
      "\tF1 for Decision_Tree:\t\t 0.7554937493581644\n",
      "\tPrecision for Decision_Tree:\t 0.7560365842619606\n",
      "\tRecall for Decision_Tree:\t\t 0.7541577039905094\n",
      "\tAccuracy for Decision_Tree:\t\t 0.7561183836084234\n",
      "\n",
      "Now classifying Linear SVM\n",
      "\tF1 for Linear SVM:\t\t 0.7843032020682474\n",
      "\tPrecision for Linear SVM:\t 0.7850356605038273\n",
      "\tRecall for Linear SVM:\t\t 0.7825622172683068\n",
      "\tAccuracy for Linear SVM:\t\t 0.7848605577689242\n",
      "\n",
      "Now classifying Random Forest\n",
      "\tF1 for Random Forest:\t\t 0.8000987426811885\n",
      "\tPrecision for Random Forest:\t 0.801177143784245\n",
      "\tRecall for Random Forest:\t\t 0.7980621064570379\n",
      "\tAccuracy for Random Forest:\t\t 0.8006545247581103\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2,random_state=109)\n",
    "\n",
    "overall_f1, overall_precision, overall_recall, overall_accuracy = train_and_evaluate(X_train, X_test, \n",
    "                                                                   y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMPROVED SYSTEM\n",
    "    Features:\n",
    "        - tf-idf matrix (negation)\n",
    "        - pos:neg words ratio\n",
    "        - review length \n",
    "        - # of noun phrases "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negation + Pos:Neg Ratio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now classifying Naive_Bayes\n",
      "\tF1 for Naive_Bayes:\t\t 0.7479565156440133\n",
      "\tPrecision for Naive_Bayes:\t 0.7472519100013661\n",
      "\tRecall for Naive_Bayes:\t\t 0.7453778664267929\n",
      "\tAccuracy for Naive_Bayes:\t\t 0.7484348321001707\n",
      "\n",
      "Now classifying Decision_Tree\n",
      "\tF1 for Decision_Tree:\t\t 0.7478103787472419\n",
      "\tPrecision for Decision_Tree:\t 0.7469860784920356\n",
      "\tRecall for Decision_Tree:\t\t 0.7467698515128998\n",
      "\tAccuracy for Decision_Tree:\t\t 0.7478656801365964\n",
      "\n",
      "Now classifying Linear SVM\n",
      "\tF1 for Linear SVM:\t\t 0.77022871355725\n",
      "\tPrecision for Linear SVM:\t 0.7692731576992697\n",
      "\tRecall for Linear SVM:\t\t 0.7692190195592753\n",
      "\tAccuracy for Linear SVM:\t\t 0.7702523240371845\n",
      "\n",
      "Now classifying Random Forest\n",
      "\tF1 for Random Forest:\t\t 0.7921248856973422\n",
      "\tPrecision for Random Forest:\t 0.7918975697275566\n",
      "\tRecall for Random Forest:\t\t 0.790676209472408\n",
      "\tAccuracy for Random Forest:\t\t 0.7922595332953898\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df_data.drop(['Sentiment', 'Length', 'Noun Phrases'], axis =1)\n",
    "X = df.to_numpy()\n",
    "y = df_data[\"Sentiment\"].to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2,random_state=109)\n",
    "overall_f1, overall_precision, overall_recall, overall_accuracy = train_and_evaluate(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negation + Pos:Neg Ratio + Noun Phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now classifying Naive_Bayes\n",
      "\tF1 for Naive_Bayes:\t\t 0.7580544167705129\n",
      "\tPrecision for Naive_Bayes:\t 0.7566450493240775\n",
      "\tRecall for Naive_Bayes:\t\t 0.7564074986637465\n",
      "\tAccuracy for Naive_Bayes:\t\t 0.7581104154809334\n",
      "\n",
      "Now classifying Decision_Tree\n",
      "\tF1 for Decision_Tree:\t\t 0.7562714079852527\n",
      "\tPrecision for Decision_Tree:\t 0.7551340061694402\n",
      "\tRecall for Decision_Tree:\t\t 0.7557651192198886\n",
      "\tAccuracy for Decision_Tree:\t\t 0.7561183836084234\n",
      "\n",
      "Now classifying Linear SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zeynepmarasli/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tF1 for Linear SVM:\t\t 0.776248752776073\n",
      "\tPrecision for Linear SVM:\t 0.7750865369825887\n",
      "\tRecall for Linear SVM:\t\t 0.7755976203823206\n",
      "\tAccuracy for Linear SVM:\t\t 0.7761335609941188\n",
      "\n",
      "Now classifying Random Forest\n",
      "\tF1 for Random Forest:\t\t 0.7945015452784358\n",
      "\tPrecision for Random Forest:\t 0.7940649218853776\n",
      "\tRecall for Random Forest:\t\t 0.7933239469670303\n",
      "\tAccuracy for Random Forest:\t\t 0.794536141149687\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df_data.drop(['Sentiment', 'Length'], axis =1)\n",
    "X = df.to_numpy()\n",
    "y = df_data[\"Sentiment\"].to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2,random_state=109)\n",
    "overall_f1, overall_precision, overall_recall, overall_accuracy = train_and_evaluate(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All features: Negation + Pos:Neg Ratio + Review length + Noun phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now classifying Naive_Bayes\n",
      "\tF1 for Naive_Bayes:\t\t 0.794264275209732\n",
      "\tPrecision for Naive_Bayes:\t 0.7937137951823019\n",
      "\tRecall for Naive_Bayes:\t\t 0.7921630359680343\n",
      "\tAccuracy for Naive_Bayes:\t\t 0.794536141149687\n",
      "\n",
      "Now classifying Decision_Tree\n",
      "\tF1 for Decision_Tree:\t\t 0.7766423630707935\n",
      "\tPrecision for Decision_Tree:\t 0.7758433770705526\n",
      "\tRecall for Decision_Tree:\t\t 0.7757994707132335\n",
      "\tAccuracy for Decision_Tree:\t\t 0.7766078542970973\n",
      "\n",
      "Now classifying Linear SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zeynepmarasli/opt/anaconda3/lib/python3.8/site-packages/sklearn/svm/_base.py:1206: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tF1 for Linear SVM:\t\t 0.7899543170267979\n",
      "\tPrecision for Linear SVM:\t 0.7900541047156797\n",
      "\tRecall for Linear SVM:\t\t 0.7883533010894269\n",
      "\tAccuracy for Linear SVM:\t\t 0.7901726427622843\n",
      "\n",
      "Now classifying Random Forest\n",
      "\tF1 for Random Forest:\t\t 0.8046288777035132\n",
      "\tPrecision for Random Forest:\t 0.8051963927361755\n",
      "\tRecall for Random Forest:\t\t 0.8027140612981867\n",
      "\tAccuracy for Random Forest:\t\t 0.8049231644849175\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df_data.drop(['Sentiment'], axis =1)\n",
    "X = df.to_numpy()\n",
    "y = df_data[\"Sentiment\"].to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size=0.2,random_state=109)\n",
    "overall_f1, overall_precision, overall_recall, overall_accuracy = train_and_evaluate(X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
